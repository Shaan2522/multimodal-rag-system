# multimodal-rag-system
Offline Multimodal RAG System for Text and Image-Based Document QA using Google's Flan-T5-Base LLM.

### ğŸ“ Project Overview
This project implements an offline Retrieval-Augmented Generation (RAG) pipeline capable of answering questions using text and/or image queries against a collection of PDF documents. 
It supports:

1. PDF-to-text and PDF-to-image conversion

2. Visual block detection in images using OpenCV

3. Embeddings generation for both text (MiniLM) and images (CLIP)

4. FAISS-based similarity search (cosine similarity)

5. Natural language answer generation via FLAN-T5

6. Tkinter-based GUI to support user queries with previewed answers

### ğŸš€ Features

ğŸ§  Multimodal QA: Accepts text, image, or both as user queries.

ğŸ–¼ï¸ Image Matching: Locates and shows the most relevant image blocks.

ğŸ” Semantic Retrieval: Uses powerful sentence and vision transformers.

ğŸ“„ PDF Support: Handles multiple PDFs offline, including scanned/visual ones.

ğŸ’¬ Answer Generation: Natural answers generated using FLAN-T5.

ğŸ–¥ï¸ GUI Frontend: User-friendly interface using Pythonâ€™s Tkinter.


### ğŸ“‚ Project Structure
```bash
offline-rag/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ images/                    # Full-page rendered images (PDF â†’ JPG)
â”‚   â”‚   â””â”€â”€ <pdf_name>/page_X.jpg
â”‚   â””â”€â”€ segmentedImages/           # Block images cropped from full pages
â”‚       â””â”€â”€ <pdf_name>/<page_number>/blocks/block_X.png
â”‚
â”œâ”€â”€ models/                        # Local huggingface models
â”‚   â”œâ”€â”€ all-MiniLM-L6-v2/
â”‚   â”œâ”€â”€ clip-vit-large-patch14/
â”‚   â””â”€â”€ google-flan-t5-base/
â”‚
â”œâ”€â”€ vector_store/                  # FAISS indices and metadata
â”‚   â”œâ”€â”€ text_index.faiss
â”‚   â”œâ”€â”€ image_index.faiss
â”‚   â”œâ”€â”€ text_metadata.json
â”‚   â””â”€â”€ image_metadata.json
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ pdf_to_images.py           # Converts PDFs to images
â”‚   â”œâ”€â”€ extract_text.py            # Extracts text per PDF page
â”‚   â”œâ”€â”€ detect_blocks.py           # Detects object blocks using OpenCV
â”‚   â”œâ”€â”€ generate_embeddings.py     # Generates and stores embeddings
â”‚   â””â”€â”€ build_faiss_index.py       # Builds FAISS index
â”‚
â”œâ”€â”€ query_rag.py                   # Main backend inference logic
â”œâ”€â”€ rag_gui.py                     # Tkinter GUI application
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # You are here
```

### ğŸ› ï¸ Installation
âœ… 1. Clone the Repository

```bash
git clone https://github.com/yourusername/offline-rag.git
cd offline-rag
```

âœ… 2. Install Python Dependencies
```bash
pip install -r requirements.txt
```

âœ… 3. Download Models Locally
Download and place the following models into the ```models/``` folder:

1. all-MiniLM-L6-v2

2. clip-vit-large-patch14

3. google/flan-t5-base

Important: All models can be used completely offline (no internet required).

### âš™ï¸ Preprocessing Pipeline

#### ğŸ“„ Step 1: PDF to Images
```bash
python scripts/pdf_to_images.py
```
Converts every page of all PDFs into .jpg images at 200 DPI.

#### ğŸ” Step 2: Text Extraction
```bash
python scripts/extract_text.py
```
Extracts per-page text using PyPDF2 (for scanned documents).

#### ğŸ§© Step 3: Visual Block Detection
```bash
python scripts/detect_blocks.py
```
Uses OpenCV to segment images into diagrams/tables/logos and stores block images.

#### ğŸ“Š Step 4: Embedding Generation
```bash
python scripts/generate_embeddings.py
```
Creates embeddings for:

1. Text (using MiniLM)

2. Images + blocks (using CLIP)

#### ğŸ§  Step 5: Build FAISS Index
```bash
python scripts/build_faiss_index.py
```
Creates ```text_index.faiss``` and ```image_index.faiss``` in the ```vector_store/``` folder.

ğŸ–¼ï¸ Using the GUI
Run the GUI with:

```bash
python rag_gui.py
```
Functionality:

1. Enter text query and/or select an image

2. Choose input type: text, image, or both

3. Click Run Query

4. View:

- Generated answer

- Matching page previews (click to open full size)

### ğŸ“¡ Offline Compatibility

- âœ… All models and operations are fully offline.

- No API calls or external dependencies at runtime.

### ğŸ’¡ Technologies Used

| Task	| Tool/Model Used |
|:-------:|:------------------:|
| PDF â†’ Image | pdf2image |
| Text Extraction | PyPDF2 |
| Object Detection | OpenCV + SSIM |
| Text Embedding | all-MiniLM-L6-v2 |
| Image Embedding	| CLIP ViT-Large-Patch14 |
| Retrieval	| FAISS |
| Generation (QA)	| FLAN-T5 Base |
| GUI	| Tkinter, PIL (ImageTk) |

### âœ… Supported Inputs
| Input Type | Description |
|:------------:|:-------------:|
| Text Only |	Search by query text (e.g., â€œwhat is BMS?â€) |
| Image Only | Match similar pages using image |
| Text + Image | Combined context from both modalities (image takes priority) |

ğŸ“Œ Example Output
```txt
ğŸ“Œ Text matched to PDF: Battery_Specs_Brochure.pdf

ğŸ“„ Matched Page Image(s):
- D:/assets/images/Battery_Specs_Brochure/page_3.jpg
- D:/assets/images/Battery_Specs_Brochure/page_4.jpg
- D:/assets/images/Battery_Specs_Brochure/page_5.jpg

ğŸ§  Answer:
The Battery Monitoring System consists of independent modules...
```

### ğŸ Future Improvements
1. OCR fallback for scanned text regions (Tesseract)

2. Custom-trained object detection (YOLO for diagrams)

3. Summarization on matched page text

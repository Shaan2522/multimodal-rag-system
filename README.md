# multimodal-rag-system
multimodal rag system for text and image querying from PDFs

ğŸ’¡ Offline Multimodal RAG System for Text and Image-Based Document QA
ğŸ“ Project Overview
This project implements an offline Retrieval-Augmented Generation (RAG) pipeline capable of answering questions using text and/or image queries against a collection of PDF documents. It supports:

PDF-to-text and image conversion

Visual block detection in images using OpenCV

Embeddings generation for both text (MiniLM) and images (CLIP)

FAISS-based similarity search

Natural language answer generation via FLAN-T5

Tkinter-based GUI to support user queries with previewed answers

ğŸš€ Features
ğŸ§  Multimodal QA: Accepts text, image, or both as user queries.

ğŸ–¼ï¸ Image Matching: Locates and shows the most relevant image blocks.

ğŸ” Semantic Retrieval: Uses powerful sentence and vision transformers.

ğŸ“„ PDF Support: Handles multiple PDFs offline, including scanned/visual ones.

ğŸ’¬ Answer Generation: Natural answers generated using FLAN-T5.

ğŸ–¥ï¸ GUI Frontend: User-friendly interface using Pythonâ€™s Tkinter.

ğŸ“‚ Project Structure
bash
Copy
Edit
offline-rag/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ images/                      # Full-page rendered images (PDF â†’ JPG)
â”‚   â”‚   â””â”€â”€ <pdf_name>/page_X.jpg
â”‚   â””â”€â”€ segmentedImages/            # Block images cropped from full pages
â”‚       â””â”€â”€ <pdf_name>/<page_number>/blocks/block_X.png
â”‚
â”œâ”€â”€ models/                          # Local huggingface models
â”‚   â”œâ”€â”€ all-MiniLM-L6-v2/
â”‚   â”œâ”€â”€ clip-vit-large-patch14/
â”‚   â””â”€â”€ google-flan-t5-base/
â”‚
â”œâ”€â”€ vector_store/                   # FAISS indices and metadata
â”‚   â”œâ”€â”€ text_index.faiss
â”‚   â”œâ”€â”€ image_index.faiss
â”‚   â”œâ”€â”€ text_metadata.json
â”‚   â””â”€â”€ image_metadata.json
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ pdf_to_images.py           # Converts PDFs to images
â”‚   â”œâ”€â”€ extract_text.py            # Extracts text per PDF page
â”‚   â”œâ”€â”€ detect_blocks.py           # Detects object blocks using OpenCV
â”‚   â”œâ”€â”€ generate_embeddings.py     # Generates and stores embeddings
â”‚   â””â”€â”€ build_faiss_index.py       # Builds FAISS index
â”‚
â”œâ”€â”€ query_rag.py                   # Main backend inference logic
â”œâ”€â”€ rag_gui.py                     # Tkinter GUI application
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # You are here
ğŸ› ï¸ Installation
âœ… 1. Clone the Repository
bash
Copy
Edit
git clone https://github.com/yourusername/offline-rag.git
cd offline-rag
âœ… 2. Install Python Dependencies
bash
Copy
Edit
pip install -r requirements.txt
Make sure you have Python 3.8+ and poppler installed (required by pdf2image).

âœ… 3. Download Models Locally
Download and place the following models into the models/ folder:

all-MiniLM-L6-v2

clip-vit-large-patch14

google/flan-t5-base

Important: All models must be used offline (no internet required).

âš™ï¸ Preprocessing Pipeline
ğŸ“„ Step 1: PDF to Images
bash
Copy
Edit
python scripts/pdf_to_images.py
Converts every page of all PDFs into .jpg images at 200 DPI.

ğŸ” Step 2: Text Extraction
bash
Copy
Edit
python scripts/extract_text.py
Extracts per-page text using PyPDF2 or Tesseract (for scanned documents).

ğŸ§© Step 3: Visual Block Detection
bash
Copy
Edit
python scripts/detect_blocks.py
Uses OpenCV to segment images into diagrams/tables/logos and stores block images.

ğŸ“Š Step 4: Embedding Generation
bash
Copy
Edit
python scripts/generate_embeddings.py
Creates embeddings for:

Text (using MiniLM)

Images + blocks (using CLIP)

ğŸ§  Step 5: Build FAISS Index
bash
Copy
Edit
python scripts/build_faiss_index.py
Creates text_index.faiss and image_index.faiss in the vector_store/ folder.

ğŸ–¼ï¸ Using the GUI
Run the GUI with:

bash
Copy
Edit
python rag_gui.py
Functionality:

Enter text query and/or select an image

Choose input type: text, image, or both

Click Run Query

View:

Generated answer

Matching page previews (click to open full size)

ğŸ“¡ Offline Compatibility
âœ… All models and operations are fully offline.
No API calls or external dependencies at runtime.

ğŸ’¡ Technologies Used
Task	Tool/Model Used
PDF â†’ Image	pdf2image
Text Extraction	PyPDF2 / Tesseract
Object Detection	OpenCV + SSIM
Text Embedding	all-MiniLM-L6-v2
Image Embedding	CLIP ViT-Large-Patch14
Retrieval	FAISS
Generation (QA)	FLAN-T5 Base
GUI	Tkinter, PIL (ImageTk)

âœ… Supported Inputs
Input Type	Description
Text Only	Search by query text (e.g., â€œwhat is BMS?â€)
Image Only	Match similar pages using image
Text + Image	Combined context from both modalities

ğŸ“Œ Example Output
txt
Copy
Edit
ğŸ“Œ Text matched to PDF: Battery_Specs_Brochure.pdf

ğŸ“„ Matched Page Image(s):
- D:/assets/images/Battery_Specs_Brochure/page_3.jpg
- D:/assets/images/Battery_Specs_Brochure/page_4.jpg
- D:/assets/images/Battery_Specs_Brochure/page_5.jpg

ğŸ§  Answer:
The Battery Monitoring System consists of independent modules...
ğŸ Future Improvements
OCR fallback for scanned text regions (Tesseract)

Custom-trained object detection (YOLO for diagrams)

Summarization on matched page text

Dockerized deployment

ğŸ§¾ License
This project is licensed for educational and non-commercial use. Contact the author for enterprise licensing.
